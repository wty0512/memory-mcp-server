# RAG Enhancement Proposal for Memory MCP Server

## ç¾ç‹€åˆ†æ / Current State Analysis

### âœ… å·²å…·å‚™çš„RAGçµ„ä»¶
- **æ–‡æª”å­˜å„²**: SQLite + FTS5å…¨æ–‡æœç´¢
- **æª¢ç´¢æ¥å£**: search_memory, search_index
- **å…§å®¹åˆ†å¡Š**: æŒ‰æ¢ç›®çµ„ç¹”ï¼Œæ”¯æŒéšå±¤çµæ§‹
- **å…ƒæ•¸æ“š**: title, category, timestamp, hierarchy_level
- **å¤šæ ¼å¼æ”¯æŒ**: Markdown, JSON, CSVå°å…¥å°å‡º

### ğŸ”„ éœ€è¦å¢å¼·çš„éƒ¨åˆ†

#### 1. å‘é‡åŒ–æª¢ç´¢ (Vector Search)
```python
# æ–°å¢å‘é‡åŒ–åŠŸèƒ½
class VectorizedMemoryBackend(SQLiteBackend):
    def __init__(self, db_path: str, embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"):
        super().__init__(db_path)
        self.embedding_model = self._load_embedding_model(embedding_model)
        self._init_vector_tables()
    
    def _init_vector_tables(self):
        """åˆå§‹åŒ–å‘é‡å­˜å„²è¡¨"""
        with self.get_connection() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS memory_embeddings (
                    entry_id INTEGER PRIMARY KEY,
                    embedding BLOB,  -- å­˜å„²å‘é‡
                    embedding_model TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (entry_id) REFERENCES memory_entries(id)
                )
            """)
    
    def add_memory_with_embedding(self, project: str, title: str, entry: str, **kwargs):
        """æ·»åŠ è¨˜æ†¶ä¸¦ç”Ÿæˆå‘é‡"""
        entry_id = super().add_memory(project, title, entry, **kwargs)
        
        # ç”Ÿæˆå‘é‡
        embedding = self._generate_embedding(f"{title} {entry}")
        
        # å­˜å„²å‘é‡
        with self.get_connection() as conn:
            conn.execute("""
                INSERT INTO memory_embeddings (entry_id, embedding, embedding_model)
                VALUES (?, ?, ?)
            """, (entry_id, embedding.tobytes(), self.embedding_model.name))
        
        return entry_id
    
    def semantic_search(self, project: str, query: str, limit: int = 10):
        """èªç¾©æœç´¢"""
        query_embedding = self._generate_embedding(query)
        
        # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢
        with self.get_connection() as conn:
            cursor = conn.execute("""
                SELECT me.*, 
                       cosine_similarity(mem.embedding, ?) as similarity
                FROM memory_entries me
                JOIN memory_embeddings mem ON me.id = mem.entry_id
                WHERE me.project = ?
                ORDER BY similarity DESC
                LIMIT ?
            """, (query_embedding.tobytes(), project, limit))
            
            return [dict(row) for row in cursor.fetchall()]
```

#### 2. æ··åˆæª¢ç´¢ç­–ç•¥ (Hybrid Retrieval)
```python
def hybrid_search(self, project: str, query: str, limit: int = 10, 
                 semantic_weight: float = 0.7, keyword_weight: float = 0.3):
    """æ··åˆæª¢ç´¢ï¼šèªç¾©æœç´¢ + é—œéµè©æœç´¢"""
    
    # èªç¾©æœç´¢çµæœ
    semantic_results = self.semantic_search(project, query, limit * 2)
    
    # é—œéµè©æœç´¢çµæœ (ç¾æœ‰çš„FTS5)
    keyword_results = self.search_mem_entries(project, query, limit * 2)
    
    # çµæœèåˆå’Œé‡æ’åº
    combined_results = self._merge_and_rerank(
        semantic_results, keyword_results, 
        semantic_weight, keyword_weight
    )
    
    return combined_results[:limit]
```

#### 3. æ™ºèƒ½åˆ†å¡Šç­–ç•¥ (Smart Chunking)
```python
def intelligent_chunking(self, content: str, max_chunk_size: int = 512):
    """æ™ºèƒ½åˆ†å¡Šï¼šä¿æŒèªç¾©å®Œæ•´æ€§"""
    
    # æŒ‰æ®µè½åˆ†å‰²
    paragraphs = content.split('\n\n')
    chunks = []
    current_chunk = ""
    
    for paragraph in paragraphs:
        if len(current_chunk + paragraph) <= max_chunk_size:
            current_chunk += paragraph + '\n\n'
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = paragraph + '\n\n'
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks
```

#### 4. RAGæŸ¥è©¢æ¥å£
```python
async def rag_query(self, project_id: str, question: str, 
                   context_limit: int = 5, max_tokens: int = 2000):
    """RAGæŸ¥è©¢ï¼šæª¢ç´¢ç›¸é—œå…§å®¹ä¸¦ç”Ÿæˆå›ç­”"""
    
    # 1. æª¢ç´¢ç›¸é—œå…§å®¹
    relevant_docs = self.hybrid_search(project_id, question, context_limit)
    
    # 2. æ§‹å»ºä¸Šä¸‹æ–‡
    context = self._build_context(relevant_docs, max_tokens)
    
    # 3. æ§‹å»ºæç¤ºè©
    prompt = f"""åŸºæ–¼ä»¥ä¸‹å°ˆæ¡ˆè¨˜æ†¶å…§å®¹å›ç­”å•é¡Œï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

å•é¡Œï¼š{question}

è«‹åŸºæ–¼ä¸Šè¿°å…§å®¹æä¾›æº–ç¢ºçš„å›ç­”ã€‚å¦‚æœå…§å®¹ä¸­æ²’æœ‰ç›¸é—œä¿¡æ¯ï¼Œè«‹æ˜ç¢ºèªªæ˜ã€‚
"""
    
    return {
        'prompt': prompt,
        'context_sources': [
            {
                'title': doc['title'],
                'timestamp': doc['created_at'],
                'similarity': doc.get('similarity', 0),
                'content_preview': doc['entry'][:200] + '...'
            }
            for doc in relevant_docs
        ]
    }
```

## å¯¦æ–½å»ºè­° / Implementation Recommendations

### éšæ®µ1ï¼šæœ€å°å¯è¡ŒRAG (2-3å¤©)
- [x] ç¾æœ‰æœç´¢åŠŸèƒ½å·²è¶³å¤ åŸºç¤RAG
- [ ] æ·»åŠ `rag_query`å·¥å…·åˆ°MCPæ¥å£
- [ ] å„ªåŒ–ç¾æœ‰æœç´¢çµæœæ’åº

### éšæ®µ2ï¼šå‘é‡åŒ–å¢å¼· (1-2é€±)
- [ ] é›†æˆsentence-transformers
- [ ] æ·»åŠ å‘é‡å­˜å„²è¡¨
- [ ] å¯¦ç¾èªç¾©æœç´¢

### éšæ®µ3ï¼šé«˜ç´šRAG (2-3é€±)  
- [ ] æ··åˆæª¢ç´¢ç­–ç•¥
- [ ] æ™ºèƒ½åˆ†å¡Š
- [ ] æŸ¥è©¢é‡å¯«å’Œæ“´å±•
- [ ] çµæœé‡æ’åº

## æŠ€è¡“é¸å‹å»ºè­°

### å‘é‡åŒ–æ¨¡å‹
- **è¼•é‡ç´š**: `sentence-transformers/all-MiniLM-L6-v2` (22MB)
- **ä¸­ç­‰**: `sentence-transformers/all-mpnet-base-v2` (420MB)  
- **å¤šèªè¨€**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`

### å‘é‡æ•¸æ“šåº«
- **SQLite + è‡ªå®šç¾©**: åˆ©ç”¨ç¾æœ‰æ¶æ§‹ï¼Œæ·»åŠ å‘é‡åˆ—
- **Chroma**: è¼•é‡ç´šå‘é‡æ•¸æ“šåº«
- **FAISS**: Facebookçš„å‘é‡æœç´¢åº«

## å·¥ä½œé‡è©•ä¼°

### ğŸŸ¢ ä½å·¥ä½œé‡ (1-2å¤©)
ä½¿ç”¨ç¾æœ‰æœç´¢åŠŸèƒ½å¯¦ç¾åŸºç¤RAGï¼Œåªéœ€æ·»åŠ ï¼š
```python
# æ–°å¢MCPå·¥å…·
{
    'name': 'rag_query',
    'description': 'åŸºæ–¼å°ˆæ¡ˆè¨˜æ†¶çš„RAGæŸ¥è©¢',
    'inputSchema': {
        'type': 'object',
        'properties': {
            'project_id': {'type': 'string'},
            'question': {'type': 'string'},
            'context_limit': {'type': 'integer', 'default': 5}
        }
    }
}
```

### ğŸŸ¡ ä¸­ç­‰å·¥ä½œé‡ (1-2é€±)
æ·»åŠ å‘é‡åŒ–æœç´¢ï¼Œéœ€è¦ï¼š
- é›†æˆembeddingæ¨¡å‹
- ä¿®æ”¹æ•¸æ“šåº«schema
- å¯¦ç¾èªç¾©æœç´¢

### ğŸ”´ é«˜å·¥ä½œé‡ (3-4é€±)
å®Œæ•´RAGç³»çµ±ï¼ŒåŒ…æ‹¬ï¼š
- é«˜ç´šæª¢ç´¢ç­–ç•¥
- æŸ¥è©¢å„ªåŒ–
- æ€§èƒ½èª¿å„ª
- å®Œæ•´æ¸¬è©¦

## çµè«–

ä½ çš„ç³»çµ±å·²ç¶“å…·å‚™äº†RAGçš„åŸºç¤æ¶æ§‹ï¼æœ€å¿«1-2å¤©å°±èƒ½å¯¦ç¾åŸºç¤RAGåŠŸèƒ½ï¼Œä¸»è¦æ˜¯æ·»åŠ ä¸€å€‹`rag_query`å·¥å…·ä¾†æ•´åˆç¾æœ‰çš„æœç´¢å’Œå…§å®¹çµ„ç¹”èƒ½åŠ›ã€‚

è¦ä¸è¦æˆ‘å¹«ä½ å¯¦ç¾ä¸€å€‹åŸºç¤ç‰ˆæœ¬çš„RAGæŸ¥è©¢åŠŸèƒ½ï¼Ÿ